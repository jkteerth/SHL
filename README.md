ğŸ™ï¸ Grammar Scoring Engine from Voice & Video

(Python | AI | Offline ASR | ML Grammar Scoring)

ğŸ“Œ Project Overview

This project is an AI-based Grammar Scoring Engine that evaluates spoken English from audio or video inputs.
It converts speech to text, corrects grammatical errors using pretrained transformer models, and produces a grammar score out of 100 with visual feedback.

The system supports:

ğŸ§ Audio upload (WAV, MP3, M4A, FLAC, OGG)

ğŸ¤ Live voice recording (Start / Stop)

ğŸ¬ Video upload (MP4, AVI, MKV, MOV â†’ audio extracted)

ğŸ“Š Grammar score visualization

ğŸŒŠ Audio waveform visualization

ğŸ–¥ï¸ Modern CustomTkinter UI

ğŸŒ Flask web version (optional)

This project was developed as part of an SHL assessment and follows industry-grade design practices.

ğŸš€ Key Features

Offline Speech Recognition (Vosk â€“ no internet required)

Grammar Correction using Transformers (T5-base)

ML-based Grammar Scoring (0â€“100)

Audio & Video Support

Waveform Visualization

Animated Score Visualization

Threaded Processing (No UI Freeze)

Cross-Platform (Windows tested)

ğŸ§  Architecture Pipeline
Audio / Video Input
        â†“
FFmpeg (Normalize & Extract Audio)
        â†“
Vosk ASR (Speech â†’ Text)
        â†“
T5 Grammar Correction Model
        â†“
Grammar Scoring Logic
        â†“
Visualization (Waveform + Score)

ğŸ“ Project Structure
SHL/
â”‚
â”œâ”€â”€ app.py                     # Main UI launcher
â”œâ”€â”€ README.md                  # Project documentation
â”œâ”€â”€ requirements.txt
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ speech_to_text.py      # Vosk ASR
â”‚   â”œâ”€â”€ grammar_corrector_ml.py
â”‚   â””â”€â”€ grammar_scorer_ml.py
â”‚
â”œâ”€â”€ audio/
â”‚   â”œâ”€â”€ recorder.py
â”‚   â””â”€â”€ audio_utils.py
â”‚
â”œâ”€â”€ video/
â”‚   â””â”€â”€ video_utils.py         # Video â†’ Audio extraction
â”‚
â”œâ”€â”€ ui/
â”‚   â””â”€â”€ main_ui.py             # CustomTkinter UI
â”‚
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ text_compare.py
â”‚
â””â”€â”€ vosk-model-en-us-0.22-lgraph/

âš™ï¸ Technologies Used
Component	Technology
Language	Python 3.11
UI	CustomTkinter
ASR	Vosk (Offline)
Grammar Correction	T5-base Transformer
Audio Processing	FFmpeg, PyDub
Visualization	Matplotlib
Threading	Python threading
Optional Web	Flask
ğŸ§ª Supported Input Formats
ğŸ§ Audio

WAV

MP3

M4A

FLAC

OGG

ğŸ¬ Video

MP4

AVI

MKV

MOV

(Video audio is extracted automatically.)

ğŸ› ï¸ Installation & Setup (Windows)
1ï¸âƒ£ Clone or Download Project
cd C:\Projects

2ï¸âƒ£ Create Virtual Environment
python -m venv venv
venv\Scripts\activate

3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

ğŸ”Š FFmpeg Setup (Required)
Download FFmpeg

https://www.gyan.dev/ffmpeg/builds/

Extract to:

C:\ffmpeg-8.0.1-essentials_build\


Add to System PATH:

C:\ffmpeg-8.0.1-essentials_build\bin


Verify:

ffmpeg -version

ğŸ§  Download Vosk Model (Offline ASR)

Download:

vosk-model-en-us-0.22-lgraph


Place it in the project root:

SHL/vosk-model-en-us-0.22-lgraph/

â–¶ï¸ Run the Application
python app.py

ğŸ–¥ï¸ How to Use

Upload Audio OR Upload Video

OR click Start Recording â†’ Stop Recording

Click Score & Process

View:

Original text

Corrected sentence

Grammar score

Waveform

Animated score chart

ğŸ“Š Grammar Scoring Logic

Grammar is corrected using a pretrained T5 transformer

Score is calculated based on:

Degree of correction

Structural differences

Score range: 0â€“100

Designed to produce realistic human-like scores

ğŸ¯ SHL Interview Explanation (Recommended)

â€œThe system uses offline speech recognition, transformer-based grammar correction, and ML-driven scoring to evaluate spoken English from audio and video inputs. It is fully offline, scalable, and reproducible.â€

ğŸ”® Future Enhancements

Browser-based microphone & camera

CEFR level prediction (A1â€“C2)

PDF report export

Web deployment (Flask / HuggingFace Spaces)

Confidence scoring per sentence

ğŸ‘¨â€ğŸ’» Author

Developed as part of an SHL AI Assessment Project
Focused on ML, NLP, and Speech Processing 
